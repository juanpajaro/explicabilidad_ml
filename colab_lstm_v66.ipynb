{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befb2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3847e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = np.load('./tokens/vocab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5527330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1000\n",
      "Vocabulary: ['' '[UNK]' 'obesidad' 'enfermedad' 'asma' 'hipotiroidismo'\n",
      " 'asma_no_especificada' 'dislipidemia' 'hipertensiÃ³n_arterial'\n",
      " 'falla_respiratoria']\n",
      "type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size:', len(vocabulary))\n",
    "print('Vocabulary:', vocabulary[:10])\n",
    "print('type:', type(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d3835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./tokens/X_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0163cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (306, 730)\n",
      "ten first elements of X_train: [[173   2  63 ...   0   0   0]\n",
      " [ 19  79  15 ...   0   0   0]\n",
      " [ 86   3 122 ...   0   0   0]\n",
      " ...\n",
      " [850 850 444 ...   0   0   0]\n",
      " [134  59   1 ...   0   0   0]\n",
      " [882 201 882 ...   0   0   0]]\n",
      "type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"ten first elements of X_train:\", X_train[:10])\n",
    "print(\"type:\", type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d998ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (306,)\n",
      "ten first elements of y_train: [0 1 1 0 0 1 1 0 1 0]\n",
      "type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_train = np.load('./tokens/y_train.npy')\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"ten first elements of y_train:\", y_train[:10])\n",
    "print(\"type:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e92097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number: 173\n",
      "number: 2\n",
      "number: 63\n",
      "number: 39\n",
      "number: 19\n",
      "number: 173\n",
      "number: 2\n",
      "number: 8\n",
      "number: 173\n",
      "number: 173\n",
      "number: 173\n",
      "number: 173\n",
      "number: 173\n",
      "number: 63\n",
      "number: 180\n",
      "number: 39\n",
      "number: 19\n",
      "number: 173\n",
      "number: 158\n",
      "number: 1\n",
      "number: 1\n",
      "number: 173\n",
      "number: 173\n",
      "number: 173\n",
      "number: 173\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "number: 0\n",
      "['calculo_del_riÃ±on', 'obesidad', 'hipotiroidismo_no_especificado', 'obesidad_no_especificada', 'hipertension_esencial_(primaria)', 'calculo_del_riÃ±on', 'obesidad', 'hipertensiÃ³n_arterial', 'calculo_del_riÃ±on', 'calculo_del_riÃ±on', 'calculo_del_riÃ±on', 'calculo_del_riÃ±on', 'calculo_del_riÃ±on', 'hipotiroidismo_no_especificado', 'obesidad_extrema_con_hipoventilacion_alveolar', 'obesidad_no_especificada', 'hipertension_esencial_(primaria)', 'calculo_del_riÃ±on', 'urolitiasis', '[UNK]', '[UNK]', 'calculo_del_riÃ±on', 'calculo_del_riÃ±on', 'calculo_del_riÃ±on', 'calculo_del_riÃ±on', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "len(X_seq): 730\n"
     ]
    }
   ],
   "source": [
    "#print(X_train[0])\n",
    "X_seq = []\n",
    "patient_n = 0\n",
    "for i in range(len(X_train[patient_n])):\n",
    "    number = X_train[patient_n][i]\n",
    "    print('number:', number)\n",
    "    enf = vocabulary[number]\n",
    "    X_seq.append(enf)\n",
    "print(X_seq)\n",
    "print('len(X_seq):', len(X_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db18a284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:00:24.288604: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-12 14:00:24.378704: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 14:00:24.782484: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-12 14:00:24.782553: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-12 14:00:24.785077: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-12 14:00:25.010496: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-12 14:00:25.012730: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-12 14:00:26.425787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Importar las librerÃ­as necesarias\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6707382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Cargar el modelo .h5 (ajusta la ruta si es necesario)\n",
    "# Por ejemplo: '/content/drive/MyDrive/modelo.h5'\n",
    "ruta_modelo = './lstm_v66.h5'\n",
    "modelo = tf.keras.models.load_model(ruta_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0820898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 730, 200)          200000    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 128)               135680    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344001 (1.31 MB)\n",
      "Trainable params: 344001 (1.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Paso 4: Mostrar resumen del modelo (incluye nombre, forma y parÃ¡metros de cada capa)\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e72d4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de la capa: embedding_1\n",
      "Nombre de la capa: bidirectional_1\n",
      "Nombre de la capa: dense_2\n",
      "Nombre de la capa: dense_3\n"
     ]
    }
   ],
   "source": [
    "# Paso 5 (opcional): Listar solo los nombres de las capas\n",
    "for capa in modelo.layers:\n",
    "    print(\"Nombre de la capa:\", capa.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e06ed4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sample shape: (306, 730)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X_sample shape:\", X_train.shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e62420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sample shape: (730,)\n",
      "[173   2  63  39  19 173   2   8 173 173 173 173 173  63 180  39  19 173\n",
      " 158   1   1 173 173 173 173   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_sample shape:\", X_train[0].shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6968e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_train[:1, :]\n",
    "print(\"X_sample shape:\", X_sample.shape)\n",
    "print(type(X_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c595b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "655c5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Seleccionar la capa desde la cual calcular el gradiente (embedding)\n",
    "embedding_layer = modelo.get_layer('embedding_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4c0a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pajaro/anaconda3/envs/ali_env_v1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-12 14:00:53,635\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from alibi.explainers import IntegratedGradients\n",
    "# 5. Inicializar IntegratedGradients con el modelo y capa de entrada\n",
    "ig = IntegratedGradients(modelo, layer=embedding_layer, n_steps=50, method='gausslegendre', internal_batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Ejecutar IG\n",
    "explanation = ig.explain(\n",
    "    X_sample,    \n",
    "    target=0,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Visualizar las atribuciones\n",
    "attributions = explanation.attributions[0]  # (100, embedding_dim)\n",
    "token_importances = np.sum(attributions, axis=-1)  # suma por embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ef7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attributions.shape)\n",
    "print(type(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43186cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token_importances.shape)\n",
    "print(type(token_importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = np.arange(len(token_importances))\n",
    "print(len(y_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que token_importances es un array 1D\n",
    "token_imp = np.array(token_importances).flatten()\n",
    "print(token_imp.shape)\n",
    "print(len(token_imp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4825245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.barh(X_seq, token_imp)\n",
    "ax.set_xlabel('Importancia')\n",
    "ax.set_title('Atribuciones de Integrated Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "phe_uniques = set(X_seq)\n",
    "print(phe_uniques)\n",
    "print(len(phe_uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = modelo(X_sample).numpy().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PredicciÃ³n:\", predictions)\n",
    "print(type(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcfd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Ejecutar IG\n",
    "explanation = ig.explain(\n",
    "    X_sample,    \n",
    "    target=predictions,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Visualizar las atribuciones\n",
    "attributions = explanation.attributions[0]  # (100, embedding_dim)\n",
    "token_importances = np.sum(attributions, axis=-1)  # suma por embedding\n",
    "# Asegurarse de que token_importances es un array 1D\n",
    "token_imp = np.array(token_importances).flatten()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.barh(X_seq, token_imp)\n",
    "ax.set_xlabel('Importancia')\n",
    "ax.set_title('Atribuciones de Integrated Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "785dca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (76, 730)\n",
      "ten first elements of X_test: [[217   3  16 ...   0   0   0]\n",
      " [134 107 134 ...   0   0   0]\n",
      " [113  59 664 ...   0   0   0]\n",
      " ...\n",
      " [102   2   2 ...   0   0   0]\n",
      " [ 76  99  99 ...   0   0   0]\n",
      " [129 258 129 ...   0   0   0]]\n",
      "type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load('./tokens/X_test.npy')\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"ten first elements of X_test:\", X_test[:10])\n",
    "print(\"type:\", type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9135b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test shape: (76,)\n",
      "ten first elements of y_test: [0 0 1 1 0 1 0 1 1 1]\n",
      "type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_test = np.load('./tokens/y_test.npy')\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"ten first elements of y_test:\", y_test[:10])\n",
    "print(\"type:\", type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79331962",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = modelo(X_test).numpy().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69fb6315",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 6. Ejecutar IG\n",
    "explanation = ig.explain(\n",
    "    X_test,    \n",
    "    target=0,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a84245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Visualizar las atribuciones\n",
    "attributions = explanation.attributions[0]  # (100, embedding_dim)\n",
    "token_importances = np.sum(attributions, axis=-1)  # suma por embedding\n",
    "# Asegurarse de que token_importances es un array 1D\n",
    "token_imp = np.array(token_importances).flatten()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.barh(X_seq, token_imp)\n",
    "ax.set_xlabel('Importancia')\n",
    "ax.set_title('Atribuciones de Integrated Gradients')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ali_env_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
